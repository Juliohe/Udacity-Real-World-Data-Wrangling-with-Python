{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Project: Cryptocurrency Analysis (BTC & ETH)\n",
    "\n",
    "## Research Question\n",
    "**How have the prices of Bitcoin (BTC) and Ethereum (ETH) correlated over the last 5 years, and what are their relative trading volumes?**\n",
    "\n",
    "This project analyzes the daily price and volume data of the two largest cryptocurrencies to understand their market relationship.\n",
    "\n",
    "## 1. Gather data\n",
    "\n",
    "In this section, we will gather data from two sources:\n",
    "1.  **Dataset 1**: Bitcoin (BTC) historical data manually downloaded from Yahoo Finance (CSV).\n",
    "2.  **Dataset 2**: Ethereum (ETH) historical data downloaded programmatically using the CoinGecko API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: Bitcoin (BTC)\n",
    "\n",
    "**Source**: Yahoo Finance\n",
    "**Method**: Manual Download\n",
    "\n",
    "**Instructions:**\n",
    "1.  Go to the Yahoo Finance page for Bitcoin: [https://finance.yahoo.com/quote/BTC-USD/history](https://finance.yahoo.com/quote/BTC-USD/history)\n",
    "2.  Set the **Time Period** to **5 Years** (or the max available if less).\n",
    "3.  Set the **Frequency** to **Daily**.\n",
    "4.  Click **Apply**.\n",
    "5.  Click **Download** to save the CSV file.\n",
    "6.  Rename the downloaded file to `btc_usd.csv`.\n",
    "7.  Create a folder named `Dataset` in your project directory (if it doesn't exist) and move the file there: `Dataset/btc_usd.csv`.\n",
    "\n",
    "*Note: The file has been pre-downloaded to the `Dataset` folder for this analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure Dataset directory exists\n",
    "if not os.path.exists('Dataset'):\n",
    "    os.makedirs('Dataset')\n",
    "\n",
    "# Load Dataset 1 (Bitcoin CSV)\n",
    "btc_path = 'Dataset/btc_usd.csv'\n",
    "\n",
    "if os.path.exists(btc_path):\n",
    "    df_btc = pd.read_csv(btc_path)\n",
    "    print(f\"Dataset 1 loaded successfully. Shape: {df_btc.shape}\")\n",
    "    display(df_btc.head())\n",
    "else:\n",
    "    print(f\"File not found: {btc_path}. Please follow the manual download instructions above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2: Ethereum (ETH)\n",
    "\n",
    "**Source**: Binance API (Alternative Source)\n",
    "**Method**: Programmatic Download\n",
    "\n",
    "We fetched the last 5 years of daily market data for Ethereum using the Binance API to ensure data consistency and volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load Dataset 2 (Ethereum CSV)\n",
    "eth_path = 'Dataset/eth_usd.csv'\n",
    "\n",
    "if os.path.exists(eth_path):\n",
    "    df_eth = pd.read_csv(eth_path)\n",
    "    print(f\"Dataset 2 loaded successfully. Shape: {df_eth.shape}\")\n",
    "    display(df_eth.head())\n",
    "else:\n",
    "    print(f\"File not found: {eth_path}. Please ensure the data gathering script has run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assess data\n",
    "\n",
    "Assess the data according to data quality and tidiness metrics.\n",
    "\n",
    "List **two** data quality issues and **two** tidiness issues. Assess each data issue visually **and** programmatically, then briefly describe the issue you find. **Make sure you include justifications for the methods you use for the assessment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issue 1: Data Type Inconsistency (Date Column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe visually\n",
    "print(\"Visual Inspection of Date column:\")\n",
    "display(df_btc[['Date']].head())\n",
    "display(df_eth[['Date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe programmatically\n",
    "print(\"BTC Data Types:\")\n",
    "print(df_btc.dtypes)\n",
    "print(\"\\nETH Data Types:\")\n",
    "print(df_eth.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: The `Date` column in both datasets is loaded as `object` (string) instead of `datetime` objects. For time-series analysis and merging, we need them to be proper datetime objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issue 2: Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe visually\n",
    "# Visual inspection might not reveal missing values in large datasets, so we rely more on programmatic checks.\n",
    "display(df_btc.info())\n",
    "display(df_eth.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe programmatically\n",
    "print(\"Missing values in BTC dataset:\")\n",
    "print(df_btc.isnull().sum())\n",
    "print(\"\\nMissing values in ETH dataset:\")\n",
    "print(df_eth.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: We need to ensure there are no missing values (NaN) in critical columns like `Close` or `Volume`. Even if the count is 0, this assessment is necessary to confirm data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issue 1: Redundant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe visually\n",
    "display(df_btc.head(2))\n",
    "display(df_eth.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe programmatically\n",
    "print(\"Columns in BTC:\", df_btc.columns.tolist())\n",
    "print(\"Columns in ETH:\", df_eth.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: The `Adj Close` column is redundant with `Close` for cryptocurrency data (they are identical). We can remove `Adj Close` to tidy the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issue 2: Datasets are Separate (Need Merging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe visually\n",
    "print(\"We currently have two separate dataframes:\")\n",
    "print(\"df_btc shape:\", df_btc.shape)\n",
    "print(\"df_eth shape:\", df_eth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dataframe programmatically\n",
    "# Check if Date ranges overlap for merging\n",
    "print(\"BTC Date Range:\", df_btc['Date'].min(), \"to\", df_btc['Date'].max())\n",
    "print(\"ETH Date Range:\", df_eth['Date'].min(), \"to\", df_eth['Date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: The observational unit is \"a day in the cryptocurrency market\". Currently, the data is split into two tables (BTC and ETH). To compare them directly (e.g., correlation, relative volume), they should be in a single table with columns like `BTC_Price`, `ETH_Price`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean data\n",
    "\n",
    "Clean the data to solve the 4 issues corresponding to data quality and tidiness found in the assessing step. **Make sure you include justifications for your cleaning decisions.**\n",
    "\n",
    "After the cleaning for each issue, please use **either** the visually or programatical method to validate the cleaning was succesful.\n",
    "\n",
    "At this stage, you are also expected to remove variables that are unnecessary for your analysis and combine your datasets. Depending on your datasets, you may choose to perform variable combination and elimination before or after the cleaning stage. Your dataset must have **at least** 4 variables after combining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Issue 1: Convert Date to datetime\n",
    "# Create copies to avoid SettingWithCopy warnings and preserve original data\n",
    "df_btc_clean = df_btc.copy()\n",
    "df_eth_clean = df_eth.copy()\n",
    "\n",
    "df_btc_clean['Date'] = pd.to_datetime(df_btc_clean['Date'])\n",
    "df_eth_clean['Date'] = pd.to_datetime(df_eth_clean['Date'])\n",
    "\n",
    "# Validate\n",
    "print(\"BTC Date Type:\", df_btc_clean['Date'].dtype)\n",
    "print(\"ETH Date Type:\", df_eth_clean['Date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Issue 2: Handle Missing Values\n",
    "# Check for missing values before dropping\n",
    "print(\"Missing before:\", df_btc_clean.isnull().sum().sum(), df_eth_clean.isnull().sum().sum())\n",
    "\n",
    "df_btc_clean.dropna(inplace=True)\n",
    "df_eth_clean.dropna(inplace=True)\n",
    "\n",
    "# Validate\n",
    "print(\"Missing after:\", df_btc_clean.isnull().sum().sum(), df_eth_clean.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary variables and combine datasets\n",
    "# 1. Remove 'Adj Close' as identified in Tidiness Issue 1\n",
    "if 'Adj Close' in df_btc_clean.columns:\n",
    "    df_btc_clean.drop(columns=['Adj Close'], inplace=True)\n",
    "if 'Adj Close' in df_eth_clean.columns:\n",
    "    df_eth_clean.drop(columns=['Adj Close'], inplace=True)\n",
    "\n",
    "# 2. Select only Price and Volume for analysis (dropping Open, High, Low)\n",
    "df_btc_clean = df_btc_clean[['Date', 'Close', 'Volume']]\n",
    "df_eth_clean = df_eth_clean[['Date', 'Close', 'Volume']]\n",
    "\n",
    "# 3. Rename columns to distinguish BTC and ETH\n",
    "df_btc_clean = df_btc_clean.rename(columns={'Close': 'Price_BTC', 'Volume': 'Volume_BTC'})\n",
    "df_eth_clean = df_eth_clean.rename(columns={'Close': 'Price_ETH', 'Volume': 'Volume_ETH'})\n",
    "\n",
    "# 4. Combine datasets on Date\n",
    "df_combined = pd.merge(df_btc_clean, df_eth_clean, on='Date', how='inner')\n",
    "\n",
    "# Validate\n",
    "print(\"Combined Data Shape:\", df_combined.shape)\n",
    "display(df_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Update your data store\n",
    "\n",
    "Update your local database/data store with the cleaned data, following best practices for storing your cleaned data:\n",
    "\n",
    "1.  Must maintain different instances of the data (raw and cleaned data)\n",
    "2.  Resourceful naming (e.g. `combined_dataset.csv`)\n",
    "3.  Compare the quantity of raw and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final cleaned dataframe\n",
    "output_path = 'Dataset/crypto_combined.csv'\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")\n",
    "print(f\"Raw BTC count: {len(df_btc)}, Raw ETH count: {len(df_eth)}\")\n",
    "print(f\"Combined Cleaned count: {len(df_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Answer the research question\n",
    "\n",
    "**4.1:** Define and answer the research question.\n",
    "\n",
    "**Question:** How have the prices of Bitcoin (BTC) and Ethereum (ETH) correlated over the last 5 years, and what are their relative trading volumes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis and Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate Correlation\n",
    "correlation = df_combined['Price_BTC'].corr(df_combined['Price_ETH'])\n",
    "print(f\"Correlation between BTC and ETH Prices: {correlation:.4f}\")\n",
    "\n",
    "# Visualization 1: Dual Axis Price Plot\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('BTC Price (USD)', color=color)\n",
    "ax1.plot(df_combined['Date'], df_combined['Price_BTC'], color=color, label='BTC Price')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('ETH Price (USD)', color=color)\n",
    "ax2.plot(df_combined['Date'], df_combined['Price_ETH'], color=color, label='ETH Price')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title(f'BTC vs ETH Price Trends (5 Years) - Correlation: {correlation:.2f}')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Scatter Plot with Trendline\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Price_BTC', y='Price_ETH', data=df_combined, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "plt.title('Correlation Scatter Plot: BTC vs ETH Prices')\n",
    "plt.xlabel('BTC Price (USD)')\n",
    "plt.ylabel('ETH Price (USD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2:** Reflection\n",
    "If I had more time to complete the project, I would..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}